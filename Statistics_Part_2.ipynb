{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yafHfELp7-He"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Part 2\n",
        "\n",
        "1. What is hypothesis testing in statistics?\n",
        "- Hypothesis testing in statistics is a formal procedure used to make inferences or decisions about a population based on sample data. It helps determine whether a specific claim (called a hypothesis) about a population parameter is supported by the data.\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "- Null Hypothesis\n",
        "\n",
        "The default or starting assumption.\n",
        "\n",
        "Represents no effect, no difference, or status quo.\n",
        "\n",
        "It is what we assume to be true unless evidence suggests otherwise.\n",
        "\n",
        "The goal is to test this hypothesis and see if we have enough evidence to reject it.\n",
        "\n",
        "- Alternative Hypothesis\n",
        "\n",
        "The research or opposing claim.\n",
        "\n",
        "Represents a new effect, difference, or change.\n",
        "\n",
        "This is what the researcher often hopes to prove.\n",
        "\n",
        "We try to find evidence to support this hypothesis by rejecting\n",
        "\n",
        "3.  What is the significance level in hypothesis testing, and why is it important?\n",
        "- The significance level, denoted by\n",
        "ùõº\n",
        "Œ± (alpha), is the threshold used to decide whether to reject the null hypothesis\n",
        "\n",
        "Why It‚Äôs Important:\n",
        " - Controls Risk of False Alarms:\n",
        "It limits how willing you are to accept that an observed effect is real when it might just be due to chance.\n",
        "\n",
        " - Balances Statistical Risk:\n",
        "Lowering\n",
        "ùõº\n",
        "Œ± reduces the risk of a Type I error but increases the risk of a Type II error (failing to detect a real effect).\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "- The p-value is the probability of obtaining a test statistic as extreme as, or more extreme than, the observed result, assuming that the null hypothesis\n",
        "ùêª\n",
        "0\n",
        "  is true.\n",
        "The p-value (short for probability value) is a key concept in hypothesis testing that helps you decide whether to reject the null hypothesis.  \n",
        "\n",
        "5.  How do you interpret the P-value in hypothesis testing?\n",
        "- The p-value helps you decide whether your sample data provides enough evidence to reject the null hypothesis\n",
        "\n",
        "6.  What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "- Type I Error (False Positive)\n",
        "\n",
        "Definition: Rejecting the null hypothesis when it is actually true.\n",
        "\n",
        "Analogy: Convicting an innocent person.\n",
        "\n",
        "Probability of Occurrence: Denoted by Œ± (significance level).\n",
        "\n",
        "You say: ‚ÄúThere is an effect,‚Äù\n",
        "\n",
        "but in reality: ‚ÄúThere isn‚Äôt.‚Äù\n",
        "\n",
        "- Type II Error (False Negative)\n",
        "\n",
        "Definition: Failing to reject the null hypothesis when it is actually false.\n",
        "\n",
        "Analogy: Letting a guilty person go free.\n",
        "\n",
        "Probability of Occurrence: Denoted by Œ≤.\n",
        "\n",
        "You say: ‚ÄúThere is no effect,‚Äù\n",
        "\n",
        "but in reality: ‚ÄúThere is.‚Äù\n",
        "\n",
        "7.  What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "- One-Tailed Test\n",
        "\n",
        "A one-tailed test checks for an effect in only one direction‚Äîeither greater than or less than a certain value.\n",
        "\n",
        "Use when:\n",
        "You‚Äôre only interested in testing if a parameter is greater than or less than a value‚Äînot both.\n",
        "\n",
        "- Two-Tailed Test\n",
        "\n",
        "A two-tailed test checks for an effect in both directions‚Äîwhether a parameter is different (either higher or lower) than a certain value.\n",
        "\n",
        "Use when:\n",
        "You're testing for any significant change‚Äînot just increase or decrease.\n",
        "\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "- A Z-test is a statistical test used to determine whether there is a significant difference between sample data and a known population parameter (like the mean or proportion), assuming the data is normally distributed.\n",
        "\n",
        "You use a Z-test when all of the following conditions are met:\n",
        "\n",
        " The population standard deviation (œÉ) is known\n",
        "\n",
        " The sample size is large (typically n‚â•30), or the population is normally distributed\n",
        "\n",
        " You're testing a mean or proportion\n",
        "\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "- A Z-score tells you how many standard deviations a data point (or sample statistic) is from the population mean.\n",
        "In hypothesis testing, it measures how far the sample mean is from the hypothesized population mean, under the assumption that the null hypothesis is true.\n",
        "\n",
        "What It Represents:\n",
        "\n",
        "The Z-score shows how extreme your sample result is under the assumption that  is true.\n",
        "\n",
        "It allows you to compare your result to the standard normal distribution (mean = 0, SD = 1).\n",
        "\n",
        "A large absolute Z-score (either very positive or very negative) suggests that the sample result is unlikely under\n",
        "\n",
        "10.  What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "- The T-distribution (also called Student‚Äôs t-distribution) is a probability distribution used in statistical inference when:\n",
        "\n",
        "The sample size is small\n",
        "\n",
        "The population standard deviation (œÉ) is unknown\n",
        "\n",
        "It looks similar to the normal distribution (bell-shaped), but:\n",
        "\n",
        "Has heavier tails (more spread), which means it accounts for more variability.\n",
        "\n",
        "As the sample size increases, it approaches the standard normal distribution (Z-distribution).\n",
        "\n",
        "Z-distribution assumes perfect knowledge of population variability (œÉ), which is rarely the case.\n",
        "\n",
        "The T-distribution adjusts for this added uncertainty by having wider tails‚Äîespecially important when working with small samples.\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "- Both Z-tests and T-tests are used to test hypotheses about population means, but they differ based on what you know about the population and the size of your sample.\n",
        "\n",
        "Feature\t                           Z-Test\t                 T-Test\n",
        "\n",
        "- Population standard deviation      Known\t                  Unknown (use sample\n",
        "standard deviation)\n",
        "\n",
        "- Distribution used\t               Standard normal distribution (Z)\t   Student‚Äôs t-distribution\n",
        "\n",
        "- Tail thickness\t                 Thinner (less uncertainty)\t  Thicker (accounts for more sampling variability)\n",
        "\n",
        "- Use case examples\t                Quality control, large-scale surveys\t                                                      Small clinical trials, educational research with small groups\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "- A t-test is a statistical method used to determine whether there is a significant difference between means, especially when:\n",
        "\n",
        "The population standard deviation is unknown\n",
        "\n",
        "The sample size is small\n",
        "\n",
        "13.  What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "- The Z-test and T-test are closely related‚Äîthey're both used to test hypotheses about population means or proportions. The main difference lies in the amount of information you have about the population and the size of your sample.\n",
        "\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "- A confidence interval is a range of values‚Äîderived from sample data‚Äîthat is likely to contain the true population parameter (like a mean or proportion) with a certain level of confidence.\n",
        "\n",
        "15.  What is the margin of error, and how does it affect the confidence interval?\n",
        "- The margin of error (MoE) is the maximum expected difference between the true population parameter and the sample estimate (like the mean or proportion), due to sampling variability.\n",
        "\n",
        "How It Affects the Confidence Interval:\n",
        "\n",
        "The margin of error determines the width of the confidence interval.\n",
        "\n",
        "Larger margin of error ‚Üí Wider confidence interval ‚Üí Less precise estimate\n",
        "\n",
        "Smaller margin of error ‚Üí Narrower confidence interval ‚Üí More precise estimate\n",
        "\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "- Bayes‚Äô Theorem is a mathematical formula that allows you to update the probability of an event based on new evidence.\n",
        "\n",
        "Reason\t                                        Significance\n",
        "\n",
        "Updates beliefs\t            Reflects how new data alters your existing knowledge\n",
        "\n",
        "Used in decision-making\t    Powers AI, diagnostics, fraud detection, and forecasting\n",
        "\n",
        "Handles uncertainty\t        Provides a formal, probabilistic framework for reasoning under uncertainty\n",
        "\n",
        "Foundation of Bayesian stats\t    Supports a flexible alternative to frequentist inference\n",
        "\n",
        "17.  What is the Chi-square distribution, and when is it used?\n",
        "- The Chi-square distribution (œá¬≤) is a right-skewed, continuous probability distribution that arises when you sum the squares of independent standard normal variables.\n",
        "\n",
        "18.  What is the Chi-square goodness of fit test, and how is it applied?\n",
        "- The Chi-Square Goodness of Fit Test is a statistical test used to determine whether a set of observed categorical data matches an expected distribution.\n",
        "\n",
        "When to Use It:\n",
        "\n",
        "Your data is categorical (e.g., colors, brands, age groups).\n",
        "\n",
        "You have an expected distribution (theoretical or historical frequencies).\n",
        "\n",
        "You want to know if the observed data fits that distribution.\n",
        "\n",
        "19.  What is the F-distribution, and when is it used in hypothesis testing?\n",
        "- The F-distribution is a continuous probability distribution that arises frequently in hypothesis testing‚Äîespecially when comparing variances or model fits.\n",
        "\n",
        "20.  What is an ANOVA test, and what are its assumptions?\n",
        "- ANOVA (Analysis of Variance) is a statistical method used to determine whether there are significant differences between the means of three or more independent groups.\n",
        "\n",
        "Assumptions of ANOVA:\n",
        "\n",
        "- Independence\n",
        "\n",
        "Observations must be independent within and between groups.\n",
        "\n",
        "- Normality\n",
        "\n",
        "The residuals (differences from group means) should be approximately normally distributed in each group.\n",
        "\n",
        "- Homogeneity of variances (homoscedasticity)\n",
        "\n",
        "All groups should have roughly equal variances.\n",
        "\n",
        "21.  What are the different types of ANOVA tests?\n",
        "- One-Way ANOVA\n",
        "\n",
        " Use when: Comparing means of 3 or more independent groups based on one factor (independent variable).\n",
        "\n",
        "- Two-Way ANOVA\n",
        "\n",
        "Use when: Comparing means across groups formed by two factors (e.g., gender & teaching method), with or without interaction.\n",
        "\n",
        "- Repeated Measures ANOVA\n",
        "\n",
        "Use when: The same subjects are measured more than once under different conditions or over time.\n",
        "\n",
        "- Mixed-Design ANOVA (Split-Plot ANOVA)\n",
        "\n",
        "Use when: You have both repeated measures and independent groups.\n",
        "\n",
        "- MANOVA (Multivariate ANOVA)\n",
        "\n",
        "Use when: You have two or more dependent variables.\n",
        "\n",
        "-  ANCOVA (Analysis of Covariance)\n",
        "\n",
        "Use when: You want to compare group means while controlling for a covariate (a continuous variable).\n",
        "\n",
        "22.  What is the F-test, and how does it relate to hypothesis testing?\n",
        "- The F-test is a statistical test that uses the F-distribution to compare two variances or evaluate model fits.\n",
        "The F-test helps test null hypotheses that compare variances or model performance.\n",
        "\n",
        "# Practical Part 1\n",
        "\n",
        "1.  Write a Python program to generate a random variable and display its value?\n",
        "- Python program that uses the random module to generate a random variable and display its value:"
      ],
      "metadata": {
        "id": "qUQFI-6r8K_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Generate a random variable from a uniform distribution [0, 1)\n",
        "random_value = random.random()\n",
        "\n",
        "# Display the value\n",
        "print(\"Generated Random Value:\", random_value)"
      ],
      "metadata": {
        "id": "1bsE2BHvgK2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF).\n"
      ],
      "metadata": {
        "id": "-bEbGuargQT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Parameters for the discrete uniform distribution\n",
        "low = 1   # inclusive lower bound\n",
        "high = 7  # exclusive upper bound (like a 6-sided die)\n",
        "\n",
        "# Create the distribution\n",
        "dist = randint(low, high)\n",
        "\n",
        "# Values the variable can take\n",
        "x = np.arange(low, high)\n",
        "\n",
        "# Calculate PMF for each value\n",
        "pmf = dist.pmf(x)\n",
        "\n",
        "# Plotting the PMF\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.stem(x, pmf, basefmt=\" \", use_line_collection=True)\n",
        "plt.title(\"PMF of Discrete Uniform Distribution (1 to 6)\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"P(X = x)\")\n",
        "plt.xticks(x)\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jBF8yAIBgckt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "- Python function that calculates the Probability Distribution Function (PDF) ‚Äî technically a Probability Mass Function (PMF) for discrete distributions ‚Äî of a Bernoulli distribution:"
      ],
      "metadata": {
        "id": "HSNrZ2oPgi3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " Python Function:\n",
        "python\n",
        "\n",
        "def bernoulli_pdf(x, p):\n",
        "    \"\"\"\n",
        "    Calculate the PMF of a Bernoulli distribution.\n",
        "\n",
        "    Parameters:\n",
        "    x (int): The outcome (0 or 1)\n",
        "    p (float): The probability of success (0 ‚â§ p ‚â§ 1)\n",
        "\n",
        "    Returns:\n",
        "    float: The probability of observing value x\n",
        "    \"\"\"\n",
        "    if x not in [0, 1]:\n",
        "        raise ValueError(\"x must be 0 or 1 for a Bernoulli distribution.\")\n",
        "    if not (0 <= p <= 1):\n",
        "        raise ValueError(\"p must be between 0 and 1.\")\n",
        "\n",
        "    return p if x == 1 else (1 - p)\n",
        "\n",
        "# Example usage:\n",
        "print(\"P(X = 0):\", bernoulli_pdf(0, 0.7))\n",
        "print(\"P(X = 1):\", bernoulli_pdf(1, 0.7))\n",
        "üß™ Output Example:\n",
        "less\n",
        "\n",
        "P(X = 0): 0.30000000000000004\n",
        "P(X = 1): 0.7"
      ],
      "metadata": {
        "id": "bejvEWfDgsnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram>\n"
      ],
      "metadata": {
        "id": "shljQXfDg4NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters\n",
        "n = 10       # number of trials\n",
        "p = 0.5      # probability of success\n",
        "size = 10000 # number of simulations\n",
        "\n",
        "# Simulate binomial distribution\n",
        "data = np.random.binomial(n, p, size)\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(data, bins=np.arange(-0.5, n + 1.5, 1), density=True, edgecolor='black', alpha=0.7, label='Simulated')\n",
        "\n",
        "# Overlay the theoretical PMF\n",
        "x = np.arange(0, n + 1)\n",
        "pmf = binom.pmf(x, n, p)\n",
        "plt.plot(x, pmf, 'o-', color='red', label='Theoretical PMF')\n",
        "\n",
        "# Plot styling\n",
        "plt.title(f'Binomial Distribution (n={n}, p={p})')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(x)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "96xmaZqyhI9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Poisson distribution and visualize it using Python.\n",
        "- Here's how you can create a Poisson distribution and visualize it using Python. The Poisson distribution is commonly used to model the number of events occurring in a fixed interval of time or space when these events occur with a known constant rate."
      ],
      "metadata": {
        "id": "Z6FeLrALhKln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameters\n",
        "lambda_val = 4       # average rate (Œª)\n",
        "x = np.arange(0, 15) # range of x values\n",
        "\n",
        "# Calculate PMF\n",
        "pmf = poisson.pmf(x, mu=lambda_val)\n",
        "\n",
        "# Plotting the PMF\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.stem(x, pmf, basefmt=\" \", use_line_collection=True)\n",
        "plt.title(f\"Poisson Distribution (Œª = {lambda_val})\")\n",
        "plt.xlabel(\"Number of Events (k)\")\n",
        "plt.ylabel(\"P(X = k)\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F9oT3RB3hX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete\n",
        "uniform distribution.\n",
        "- Python program to calculate and plot the Cumulative Distribution Function (CDF) of a discrete uniform distribution using scipy.stats and matplotlib."
      ],
      "metadata": {
        "id": "xQBU25zghawq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Parameters for the discrete uniform distribution\n",
        "low = 1   # inclusive lower bound\n",
        "high = 7  # exclusive upper bound (so this simulates values 1 to 6)\n",
        "\n",
        "# Define distribution\n",
        "dist = randint(low, high)\n",
        "\n",
        "# Values in the domain\n",
        "x = np.arange(low - 1, high + 1)\n",
        "\n",
        "# Calculate CDF values\n",
        "cdf = dist.cdf(x)\n",
        "\n",
        "# Plotting the CDF\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.step(x, cdf, where='post', label='CDF', color='blue')\n",
        "plt.title(\"CDF of Discrete Uniform Distribution (1 to 6)\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"P(X ‚â§ x)\")\n",
        "plt.xticks(np.arange(low - 1, high + 1))\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fwHzbho1hnjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Generate a continuous uniform distribution using NumPy and visualize it.\n",
        "-  continuous uniform distribution has equal probability across a continuous interval"
      ],
      "metadata": {
        "id": "3mnX1RrChqVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the continuous uniform distribution\n",
        "a = 2     # lower bound\n",
        "b = 5     # upper bound\n",
        "size = 10000  # number of random samples\n",
        "\n",
        "# Generate random samples from uniform distribution\n",
        "data = np.random.uniform(low=a, high=b, size=size)\n",
        "\n",
        "# Plot histogram (empirical distribution)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(data, bins=50, density=True, color='skyblue', edgecolor='black', alpha=0.7, label='Histogram (samples)')\n",
        "\n",
        "# Plot the theoretical PDF\n",
        "plt.hlines(1 / (b - a), xmin=a, xmax=b, colors='red', linewidth=2, label='Theoretical PDF')\n",
        "\n",
        "# Plot styling\n",
        "plt.title(f\"Continuous Uniform Distribution U({a}, {b})\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yolwuCJNh2kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Simulate data from a normal distribution and plot its histogram.\n",
        "- simulate data from a normal (Gaussian) distribution and plot its histogram using Python."
      ],
      "metadata": {
        "id": "J5atQFgah5vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mu = 0      # mean\n",
        "sigma = 1   # standard deviation\n",
        "size = 10000  # number of data points\n",
        "\n",
        "# Simulate data\n",
        "data = np.random.normal(loc=mu, scale=sigma, size=size)\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "count, bins, ignored = plt.hist(data, bins=50, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Simulated Data')\n",
        "\n",
        "# Plot the theoretical PDF\n",
        "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
        "pdf = norm.pdf(x, mu, sigma)\n",
        "plt.plot(x, pdf, 'r--', label='Theoretical PDF')\n",
        "\n",
        "# Styling\n",
        "plt.title(\"Histogram of Simulated Normal Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "URmIhREUiGeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python function to calculate Z-scores from a dataset and plot them.\n",
        "- Python function that:\n",
        "\n",
        "Calculates Z-scores for a given dataset\n",
        "\n",
        "Plots the Z-scores using a simple scatter plot and histogram"
      ],
      "metadata": {
        "id": "0scc0iLOiHsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): A list or NumPy array of numerical values.\n",
        "    \"\"\"\n",
        "    # Convert to NumPy array for calculation\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    # Calculate Z-scores\n",
        "    z_scores = (data - mean) / std\n",
        "\n",
        "    # Plot Z-scores (scatter plot)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(range(len(z_scores)), z_scores, color='blue', alpha=0.6)\n",
        "    plt.axhline(0, color='gray', linestyle='--')\n",
        "    plt.title(\"Z-scores Scatter Plot\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Z-score\")\n",
        "\n",
        "    # Plot histogram of Z-scores\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    plt.title(\"Z-scores Histogram\")\n",
        "    plt.xlabel(\"Z-score\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate sample data (e.g., normal distribution)\n",
        "    sample_data = np.random.normal(loc=100, scale=15, size=100)\n",
        "    z_scores = calculate_and_plot_z_scores(sample_data)\n"
      ],
      "metadata": {
        "id": "a21ZTfKjiYpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n",
        "- Central Limit Theorem (CLT) using Python by:\n",
        "\n",
        "Sampling from a non-normal distribution (e.g., exponential distribution)\n",
        "\n",
        "Taking multiple sample means from that distribution\n",
        "\n",
        "Showing how those means form a normal distribution as sample size increases"
      ],
      "metadata": {
        "id": "iP7Yv2BmiZw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): A list or NumPy array of numerical values.\n",
        "    \"\"\"\n",
        "    # Convert to NumPy array for calculation\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    # Calculate Z-scores\n",
        "    z_scores = (data - mean) / std\n",
        "\n",
        "    # Plot Z-scores (scatter plot)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(range(len(z_scores)), z_scores, color='blue', alpha=0.6)\n",
        "    plt.axhline(0, color='gray', linestyle='--')\n",
        "    plt.title(\"Z-scores Scatter Plot\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Z-score\")\n",
        "\n",
        "    # Plot histogram of Z-scores\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    plt.title(\"Z-scores Histogram\")\n",
        "    plt.xlabel(\"Z-score\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate sample data (e.g., normal distribution)\n",
        "    sample_data = np.random.normal(loc=100, scale=15, size=100)\n",
        "    z_scores = calculate_and_plot_z_scores(sample_data)\n"
      ],
      "metadata": {
        "id": "zFNTuIlFirTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem.\n",
        "- To simulate multiple samples from a non-normal distribution and verify the Central Limit Theorem (CLT) using Python, we‚Äôll go through these steps:\n",
        "\n",
        "Python Simulation Plan:\n",
        "Generate a non-normal population (e.g., exponential).\n",
        "\n",
        "Draw multiple random samples from this population.\n",
        "\n",
        "Compute the mean of each sample.\n",
        "\n",
        "Plot the distribution of these sample means.\n",
        "\n",
        "Overlay a normal distribution curve to show convergence."
      ],
      "metadata": {
        "id": "sxHg5GTVis77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Create a non-normal population (exponential distribution)\n",
        "population = np.random.exponential(scale=2, size=100000)\n",
        "\n",
        "# Step 2: Parameters\n",
        "sample_size = 50      # n ‚â• 30 for CLT\n",
        "num_samples = 1000    # Number of samples\n",
        "sample_means = []\n",
        "\n",
        "# Step 3: Take multiple samples and compute sample means\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Step 4: Plotting\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(sample_means, kde=True, stat='density', bins=30, color='skyblue', label='Sample Means Distribution')\n",
        "\n",
        "# Overlay Normal Distribution\n",
        "mean = np.mean(sample_means)\n",
        "std = np.std(sample_means)\n",
        "x = np.linspace(min(sample_means), max(sample_means), 100)\n",
        "plt.plot(x, norm.pdf(x, mean, std), 'r', label='Normal PDF')\n",
        "\n",
        "plt.title('Central Limit Theorem Demonstration')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yP8g2apNjB8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.  Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1).\n",
        "-"
      ],
      "metadata": {
        "id": "x_gw1oP3jDc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "    # Define the range for the x-axis\n",
        "    x = np.linspace(-4, 4, 1000)  # from -4 to 4 standard deviations\n",
        "\n",
        "    # Calculate the PDF of the standard normal distribution\n",
        "    y = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y, color='blue', lw=2, label='Standard Normal PDF')\n",
        "    plt.fill_between(x, y, color='skyblue', alpha=0.4)\n",
        "    plt.title('Standard Normal Distribution (mean = 0, std = 1)')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.axvline(0, color='black', linestyle='--', label='Mean = 0')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_standard_normal_distribution()\n"
      ],
      "metadata": {
        "id": "wEK8lUkIjQ5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Generate random variables and calculate their corresponding probabilities using the binomial distribution.\n",
        "- Python example to generate random variables and calculate their corresponding probabilities using the Binomial distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "VPxBI-2jjR-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binom\n",
        "\n",
        "def simulate_binomial(n=10, p=0.6, size=1000):\n",
        "    # Step 1: Generate binomial random variables\n",
        "    data = np.random.binomial(n=n, p=p, size=size)\n",
        "\n",
        "    # Step 2: Unique outcomes and their frequencies\n",
        "    values, counts = np.unique(data, return_counts=True)\n",
        "\n",
        "    # Step 3: Calculate theoretical binomial probabilities\n",
        "    x = np.arange(0, n+1)\n",
        "    probabilities = binom.pmf(x, n, p)\n",
        "\n",
        "    # Step 4: Plot empirical vs theoretical probabilities\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x, probabilities, alpha=0.6, label='Theoretical PMF', color='blue')\n",
        "    plt.bar(values, counts/size, alpha=0.4, label='Empirical Frequencies', color='orange')\n",
        "    plt.title(f'Binomial Distribution (n={n}, p={p})')\n",
        "    plt.xlabel('Number of Successes')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Run the simulation\n",
        "simulate_binomial()\n"
      ],
      "metadata": {
        "id": "555ro-iCjdRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal\n",
        "distribution."
      ],
      "metadata": {
        "id": "AaL5UrOojeZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_z_score(x, mean, std_dev):\n",
        "    \"\"\"Calculate the Z-score of a data point.\"\"\"\n",
        "    return (x - mean) / std_dev\n",
        "\n",
        "def plot_standard_normal_with_z(x, mean, std_dev):\n",
        "    z = calculate_z_score(x, mean, std_dev)\n",
        "\n",
        "    # Define range for standard normal curve\n",
        "    x_vals = np.linspace(-4, 4, 1000)\n",
        "    y_vals = norm.pdf(x_vals, loc=0, scale=1)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x_vals, y_vals, label='Standard Normal Distribution', color='blue')\n",
        "    plt.fill_between(x_vals, y_vals, where=(x_vals <= z), color='skyblue', alpha=0.5)\n",
        "    plt.axvline(z, color='red', linestyle='--', label=f'Z-score = {z:.2f}')\n",
        "    plt.title('Z-score and Standard Normal Distribution')\n",
        "    plt.xlabel('Z')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Output\n",
        "    print(f\"Data point: {x}\")\n",
        "    print(f\"Mean: {mean}, Standard Deviation: {std_dev}\")\n",
        "    print(f\"Z-score: {z:.2f}\")\n",
        "    print(f\"Area to the left of Z (CDF): {norm.cdf(z):.4f}\")\n",
        "    print(f\"Area to the right of Z: {1 - norm.cdf(z):.4f}\")\n",
        "\n",
        "# Example usage\n",
        "data_point = 85\n",
        "population_mean = 70\n",
        "population_std = 10\n",
        "\n",
        "plot_standard_normal_with_z(data_point, population_mean, population_std)\n"
      ],
      "metadata": {
        "id": "WcBHck4_jnyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Implement hypothesis testing using Z-statistics for a sample dataset.\n",
        "- Python program to implement hypothesis testing using Z-statistics for a sample dataset."
      ],
      "metadata": {
        "id": "cdwWzYTYjq7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample_data, population_mean, population_std, alpha=0.05, alternative='two-sided'):\n",
        "    # Step 1: Sample statistics\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Step 2: Calculate Z-statistic\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "    z_stat = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Step 3: Calculate p-value\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"Alternative must be 'two-sided', 'greater', or 'less'.\")\n",
        "\n",
        "    # Step 4: Decision\n",
        "    result = \"Reject null hypothesis\" if p_value < alpha else \"Fail to reject null hypothesis\"\n",
        "\n",
        "    # Step 5: Output\n",
        "    print(f\"Sample Mean = {sample_mean:.2f}\")\n",
        "    print(f\"Z-Statistic = {z_stat:.4f}\")\n",
        "    print(f\"P-Value = {p_value:.4f}\")\n",
        "    print(f\"Decision: {result}\")\n",
        "\n",
        "# Example dataset and test\n",
        "sample_scores = [72, 68, 75, 70, 69, 74, 71, 73, 67, 70]\n",
        "population_mean = 70\n",
        "population_std = 5  # Assume known (Z-test condition)\n",
        "\n",
        "z_test(sample_scores, population_mean, population_std, alpha=0.05, alternative='two-sided')\n"
      ],
      "metadata": {
        "id": "2ipoykxsj4FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Create a confidence interval for a dataset using Python and interpret the result.\n",
        "- create a confidence interval for a dataset using Python and interpret the result."
      ],
      "metadata": {
        "id": "xNwfNXkHj6lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    # Sample statistics\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # standard error of the mean\n",
        "\n",
        "    # t critical value for two-tailed interval\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    # Confidence interval\n",
        "    margin_of_error = t_crit * std_err\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Sample Mean = {mean:.2f}\")\n",
        "    print(f\"{int(confidence * 100)}% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "\n",
        "    return (lower_bound, upper_bound)\n",
        "\n",
        "# Example data\n",
        "sample_data = [72, 68, 75, 70, 69, 74, 71, 73, 67, 70]\n",
        "confidence_interval(sample_data, confidence=0.95)\n"
      ],
      "metadata": {
        "id": "wE79_5EXkEKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.  Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean.\n"
      ],
      "metadata": {
        "id": "vSjPtkG_kIPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Generate data from a normal distribution\n",
        "np.random.seed(42)  # for reproducibility\n",
        "mean_true = 100\n",
        "std_true = 15\n",
        "sample_size = 50\n",
        "\n",
        "data = np.random.normal(loc=mean_true, scale=std_true, size=sample_size)\n",
        "\n",
        "# Step 2: Calculate confidence interval\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    sample_mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # standard error of the mean\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "    margin = t_crit * std_err\n",
        "    lower = sample_mean - margin\n",
        "    upper = sample_mean + margin\n",
        "\n",
        "    print(f\"Sample Mean = {sample_mean:.2f}\")\n",
        "    print(f\"{int(confidence*100)}% Confidence Interval: ({lower:.2f}, {upper:.2f})\")\n",
        "    return (lower, upper)\n",
        "\n",
        "# Step 3: Run it\n",
        "confidence_interval(data, confidence=0.95)\n"
      ],
      "metadata": {
        "id": "axYm_-UJkOzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution.\n",
        "- Python script that calculates and visualizes the Probability Density Function (PDF) of a normal distribution."
      ],
      "metadata": {
        "id": "2dfevQZ6kR9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_normal_pdf(mean=0, std_dev=1):\n",
        "    # Generate a range of x values (¬±4œÉ)\n",
        "    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "\n",
        "    # Calculate the PDF\n",
        "    pdf = norm.pdf(x, loc=mean, scale=std_dev)\n",
        "\n",
        "    # Plot the PDF\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf, color='blue', lw=2, label=f'N({mean}, {std_dev}¬≤)')\n",
        "    plt.fill_between(x, pdf, alpha=0.3, color='skyblue')\n",
        "    plt.title('Normal Distribution PDF')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.axvline(mean, color='red', linestyle='--', label='Mean')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_normal_pdf(mean=100, std_dev=15)\n"
      ],
      "metadata": {
        "id": "brL721Oxkhid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution.\n"
      ],
      "metadata": {
        "id": "RKbNiGsNkihc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "def poisson_cdf(lambda_val=4, max_k=15):\n",
        "    # Values for which we calculate CDF\n",
        "    x = np.arange(0, max_k + 1)\n",
        "\n",
        "    # Calculate CDF\n",
        "    cdf = poisson.cdf(x, mu=lambda_val)\n",
        "\n",
        "    # Display CDF values\n",
        "    for k, prob in zip(x, cdf):\n",
        "        print(f\"P(X ‚â§ {k}) = {prob:.4f}\")\n",
        "\n",
        "    # Plotting the CDF\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.step(x, cdf, where='post', label=f'Poisson CDF (Œª={lambda_val})', color='blue')\n",
        "    plt.xlabel('k')\n",
        "    plt.ylabel('P(X ‚â§ k)')\n",
        "    plt.title('Cumulative Distribution Function of Poisson Distribution')\n",
        "    plt.grid(True)\n",
        "    plt.xticks(x)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "poisson_cdf(lambda_val=4, max_k=15)\n"
      ],
      "metadata": {
        "id": "RbBGnB7yksn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  Simulate a random variable using a continuous uniform distribution and calculate its expected value.\n"
      ],
      "metadata": {
        "id": "zS99pvb-ktwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_uniform(a=10, b=20, n=10000):\n",
        "    # Step 1: Generate n uniform random variables between a and b\n",
        "    data = np.random.uniform(low=a, high=b, size=n)\n",
        "\n",
        "    # Step 2: Calculate theoretical and empirical expected value\n",
        "    theoretical_mean = (a + b) / 2\n",
        "    empirical_mean = np.mean(data)\n",
        "\n",
        "    # Output results\n",
        "    print(f\"Theoretical Expected Value = {theoretical_mean:.2f}\")\n",
        "    print(f\"Empirical Mean from Simulation (n={n}) = {empirical_mean:.2f}\")\n",
        "\n",
        "# Run the simulation\n",
        "simulate_uniform(a=10, b=20, n=10000)\n"
      ],
      "metadata": {
        "id": "QGV9zDhelDbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to compare the standard deviations of two datasets and visualize the difference.\n"
      ],
      "metadata": {
        "id": "cIh0LsVmk9Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def compare_std(dataset1, dataset2, label1='Dataset 1', label2='Dataset 2'):\n",
        "    # Step 1: Calculate standard deviations\n",
        "    std1 = np.std(dataset1, ddof=1)\n",
        "    std2 = np.std(dataset2, ddof=1)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{label1} - Standard Deviation: {std1:.2f}\")\n",
        "    print(f\"{label2} - Standard Deviation: {std2:.2f}\")\n",
        "\n",
        "    # Step 2: Visualization\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Histogram comparison\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(dataset1, kde=True, color='blue', label=label1, stat='density', alpha=0.6)\n",
        "    sns.histplot(dataset2, kde=True, color='orange', label=label2, stat='density', alpha=0.6)\n",
        "    plt.title('Histogram Comparison')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "\n",
        "    # Boxplot comparison\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(data=[dataset1, dataset2])\n",
        "    plt.xticks([0, 1], [label1, label2])\n",
        "    plt.title('Boxplot Comparison')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=5, size=100)\n",
        "data2 = np.random.normal(loc=50, scale=15, size=100)\n",
        "\n",
        "# Run the comparison\n",
        "compare_std(data1, data2, label1='Low Variance', label2='High Variance')\n"
      ],
      "metadata": {
        "id": "S0h39amulRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.  Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution.\n"
      ],
      "metadata": {
        "id": "EZLC_95IlVSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def calculate_range_and_iqr(mean=100, std_dev=15, size=1000):\n",
        "    # Step 1: Generate data from a normal distribution\n",
        "    np.random.seed(0)\n",
        "    data = np.random.normal(loc=mean, scale=std_dev, size=size)\n",
        "\n",
        "    # Step 2: Calculate range\n",
        "    data_range = np.max(data) - np.min(data)\n",
        "\n",
        "    # Step 3: Calculate IQR\n",
        "    q1 = np.percentile(data, 25)\n",
        "    q3 = np.percentile(data, 75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    # Output\n",
        "    print(f\"Range = {data_range:.2f}\")\n",
        "    print(f\"Interquartile Range (IQR) = {iqr:.2f}\")\n",
        "\n",
        "    # Step 4: Visualize with a boxplot\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(x=data)\n",
        "    plt.title('Boxplot of Normally Distributed Data')\n",
        "    plt.xlabel('Value')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Run the function\n",
        "calculate_range_and_iqr(mean=100, std_dev=15, size=1000)\n"
      ],
      "metadata": {
        "id": "wGSfpgSileDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Implement Z-score normalization on a dataset and visualize its transformation.\n",
        "- Here's a complete Python program that:\n",
        "\n",
        "Generates a dataset (from any distribution ‚Äì we'll use normal here).\n",
        "\n",
        "Applies Z-score normalization (also called standardization).\n",
        "\n",
        "Visualizes the original vs. normalized data using histograms and boxplots."
      ],
      "metadata": {
        "id": "_CnaInfYlfFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def z_score_normalization_demo(size=1000):\n",
        "    # Step 1: Generate synthetic data (skewed or normal)\n",
        "    np.random.seed(42)\n",
        "    data = np.random.normal(loc=100, scale=15, size=size)\n",
        "\n",
        "    # Step 2: Calculate Z-scores\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    z_scores = (data - mean) / std\n",
        "\n",
        "    # Step 3: Output statistics\n",
        "    print(f\"Original Data: Mean = {mean:.2f}, Std Dev = {std:.2f}\")\n",
        "    print(f\"Normalized Data: Mean = {np.mean(z_scores):.2f}, Std Dev = {np.std(z_scores):.2f}\")\n",
        "\n",
        "    # Step 4: Plot original vs. normalized\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(data, kde=True, color='skyblue')\n",
        "    plt.title('Original Data Distribution')\n",
        "    plt.xlabel('Value')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(z_scores, kde=True, color='orange')\n",
        "    plt.title('Z-score Normalized Distribution')\n",
        "    plt.xlabel('Z-score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Optional: boxplot comparison\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(data=[data, z_scores])\n",
        "    plt.xticks([0, 1], ['Original', 'Normalized'])\n",
        "    plt.title('Boxplot Comparison')\n",
        "    plt.show()\n",
        "\n",
        "# Run the demo\n",
        "z_score_normalization_demo()\n"
      ],
      "metadata": {
        "id": "ITpNo_RdlpfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal\n",
        "distribution.\n",
        "- Here's a Python function that:\n",
        "\n",
        "Generates a dataset from a normal distribution.\n",
        "\n",
        "Calculates its skewness and kurtosis.\n",
        "\n",
        "Optionally interprets the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XxTEOAKflsvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def analyze_normal_distribution_stats(mean=0, std_dev=1, size=1000):\n",
        "    # Step 1: Generate normal data\n",
        "    np.random.seed(0)\n",
        "    data = np.random.normal(loc=mean, scale=std_dev, size=size)\n",
        "\n",
        "    # Step 2: Calculate skewness and kurtosis\n",
        "    skewness = skew(data)\n",
        "    kurt = kurtosis(data, fisher=False)       # Normal: kurtosis = 3\n",
        "    excess_kurt = kurtosis(data, fisher=True) # Normal: excess kurtosis = 0\n",
        "\n",
        "    # Step 3: Print results\n",
        "    print(f\"Generated Normal Data (mean={mean}, std={std_dev}, n={size})\")\n",
        "    print(f\"Skewness: {skewness:.4f}\")\n",
        "    print(f\"Kurtosis: {kurt:.4f}  (Excess Kurtosis: {excess_kurt:.4f})\")\n",
        "\n",
        "    # Step 4: Interpretation\n",
        "    interpretation = \"\"\n",
        "    if abs(skewness) < 0.5:\n",
        "        interpretation += \"‚úÖ Data is approximately symmetric.\\n\"\n",
        "    else:\n",
        "        interpretation += \"‚ö†Ô∏è Data is skewed.\\n\"\n",
        "\n",
        "    if abs(excess_kurt) < 0.5:\n",
        "        interpretation += \"‚úÖ Data has normal-like tails (mesokurtic).\"\n",
        "    elif excess_kurt > 0.5:\n",
        "        interpretation += \"üî∫ Data has heavy tails (leptokurtic).\"\n",
        "    else:\n",
        "        interpretation += \"üîª Data has light tails (platykurtic).\"\n",
        "\n",
        "    print(\"\\nInterpretation:\\n\" + interpretation)\n",
        "\n",
        "# Run the function\n",
        "analyze_normal_distribution_stats(mean=0, std_dev=1, size=1000)\n"
      ],
      "metadata": {
        "id": "D9KpOCsPl1av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Part 2\n",
        "\n",
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results.\n"
      ],
      "metadata": {
        "id": "OesrwcEul6ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test_mean(sample_data, population_mean, population_std, alpha=0.05, alternative='two-sided'):\n",
        "    # Step 1: Sample statistics\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Step 2: Compute Z-statistic\n",
        "    z_stat = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Step 3: Compute p-value based on the alternative hypothesis\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"Alternative must be 'two-sided', 'greater', or 'less'\")\n",
        "\n",
        "    # Step 4: Decision\n",
        "    decision = \"Reject the null hypothesis\" if p_value < alpha else \"Fail to reject the null hypothesis\"\n",
        "\n",
        "    # Step 5: Output\n",
        "    print(\"----- Z-Test Result -----\")\n",
        "    print(f\"Sample Mean = {sample_mean:.2f}\")\n",
        "    print(f\"Population Mean = {population_mean}\")\n",
        "    print(f\"Z-Statistic = {z_stat:.4f}\")\n",
        "    print(f\"P-Value = {p_value:.4f}\")\n",
        "    print(f\"Significance Level (alpha) = {alpha}\")\n",
        "    print(f\"Decision: {decision}\")\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(1)\n",
        "sample = np.random.normal(loc=103, scale=15, size=40)  # Sample with mean ‚âà103\n",
        "population_mean = 100\n",
        "population_std = 15  # Known population standard deviation\n",
        "\n",
        "z_test_mean(sample, population_mean, population_std, alpha=0.05, alternative='two-sided')\n"
      ],
      "metadata": {
        "id": "JW9Xv57ImQZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n"
      ],
      "metadata": {
        "id": "lSl0BnKfmRvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulate random data (e.g., sample of exam scores)\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=75, scale=10, size=50)  # mean=75, std=10, n=50\n",
        "\n",
        "# 2. Hypothesized population mean (e.g., national average)\n",
        "mu_0 = 70  # null hypothesis: population mean is 70\n",
        "\n",
        "# 3. Perform one-sample t-test\n",
        "t_stat, p_value = stats.ttest_1samp(sample_data, mu_0)\n",
        "\n",
        "# 4. Display results\n",
        "print(f\"Sample Mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# 5. Visualize the data\n",
        "plt.hist(sample_data, bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(mu_0, color='red', linestyle='dashed', label=f'H0 Mean = {mu_0}')\n",
        "plt.axvline(np.mean(sample_data), color='green', linestyle='dashed', label='Sample Mean')\n",
        "plt.title(\"Histogram of Simulated Sample Data\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MOKCRYidmlne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n"
      ],
      "metadata": {
        "id": "vJkRdMCzmmxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Generate sample data\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=72, scale=10, size=40)  # Sample with mean 72, std 10\n",
        "\n",
        "# 2. Known population parameters\n",
        "mu_0 = 70          # Population mean under H0\n",
        "sigma = 10         # Known population standard deviation\n",
        "n = len(sample)    # Sample size\n",
        "\n",
        "# 3. Calculate sample mean\n",
        "sample_mean = np.mean(sample)\n",
        "\n",
        "# 4. Calculate Z statistic\n",
        "z = (sample_mean - mu_0) / (sigma / np.sqrt(n))\n",
        "\n",
        "# 5. Calculate two-tailed p-value\n",
        "p_value = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "# 6. Print results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-statistic: {z:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# 7. Optional: Visualize the normal distribution and test statistic\n",
        "x_vals = np.linspace(-4, 4, 1000)\n",
        "plt.plot(x_vals, norm.pdf(x_vals), label='Standard Normal PDF', color='blue')\n",
        "plt.axvline(z, color='red', linestyle='--', label=f'Z = {z:.2f}')\n",
        "plt.axvline(-z, color='red', linestyle='--')\n",
        "plt.title(\"One-Sample Z-Test Visualization\")\n",
        "plt.xlabel(\"Z-value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rhx7LkCimx_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n"
      ],
      "metadata": {
        "id": "n029cvpWm1y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulate sample data\n",
        "np.random.seed(1)\n",
        "sample = np.random.normal(loc=103, scale=15, size=50)  # Sample mean ~103, pop std dev = 15\n",
        "mu_0 = 100      # Hypothesized population mean\n",
        "sigma = 15      # Known population standard deviation\n",
        "n = len(sample)\n",
        "\n",
        "# 2. Calculate test statistic\n",
        "sample_mean = np.mean(sample)\n",
        "z = (sample_mean - mu_0) / (sigma / np.sqrt(n))\n",
        "\n",
        "# 3. Calculate two-tailed p-value\n",
        "p_value = 2 * (1 - norm.cdf(abs(z)))\n",
        "\n",
        "# 4. Print results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-statistic: {z:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# 5. Visualization\n",
        "alpha = 0.05\n",
        "z_critical = norm.ppf(1 - alpha/2)  # Two-tailed critical value\n",
        "\n",
        "# X-axis for standard normal curve\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "# Plot standard normal distribution\n",
        "plt.plot(x, y, label='Standard Normal Distribution', color='blue')\n",
        "\n",
        "# Shade rejection regions\n",
        "plt.fill_between(x, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.3, label='Rejection Region')\n",
        "\n",
        "# Plot the observed Z-statistic\n",
        "plt.axvline(z, color='black', linestyle='--', label=f'Z-stat = {z:.2f}')\n",
        "plt.axvline(-z, color='black', linestyle='--')\n",
        "\n",
        "# Labels and legend\n",
        "plt.title('Two-Tailed Z-Test')\n",
        "plt.xlabel('Z-value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.axvline(z_critical, color='red', linestyle='dotted', label=f'¬±Z-critical = ¬±{z_critical:.2f}')\n",
        "plt.axvline(-z_critical, color='red', linestyle='dotted')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BCMs6Lf3m_Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n"
      ],
      "metadata": {
        "id": "vlbo2pL1nKUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_type1_type2_errors(mu_0=100, mu_1=105, sigma=15, n=50, alpha=0.05, test='right'):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II errors for a one-tailed Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - mu_0: mean under H0\n",
        "    - mu_1: mean under H1\n",
        "    - sigma: known population standard deviation\n",
        "    - n: sample size\n",
        "    - alpha: significance level (Type I error rate)\n",
        "    - test: 'right' or 'left' for one-tailed test\n",
        "    \"\"\"\n",
        "\n",
        "    # Standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Critical value and rejection region\n",
        "    if test == 'right':\n",
        "        z_crit = norm.ppf(1 - alpha)\n",
        "        x_crit = mu_0 + z_crit * se\n",
        "        beta = norm.cdf((x_crit - mu_1) / se)\n",
        "    elif test == 'left':\n",
        "        z_crit = norm.ppf(alpha)\n",
        "        x_crit = mu_0 + z_crit * se\n",
        "        beta = 1 - norm.cdf((x_crit - mu_1) / se)\n",
        "    else:\n",
        "        raise ValueError(\"test must be either 'right' or 'left'\")\n",
        "\n",
        "    # X range for plotting\n",
        "    x = np.linspace(mu_0 - 4 * se, mu_1 + 4 * se, 1000)\n",
        "\n",
        "    # Null and alternative distributions\n",
        "    y0 = norm.pdf(x, mu_0, se)\n",
        "    y1 = norm.pdf(x, mu_1, se)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y0, label='H‚ÇÄ Distribution', color='blue')\n",
        "    plt.plot(x, y1, label='H‚ÇÅ Distribution', color='green')\n",
        "\n",
        "    # Shade Type I error (Œ±)\n",
        "    if test == 'right':\n",
        "        plt.fill_between(x, y0, where=(x >= x_crit), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "    else:\n",
        "        plt.fill_between(x, y0, where=(x <= x_crit), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "\n",
        "    # Shade Type II error (Œ≤)\n",
        "    if test == 'right':\n",
        "        plt.fill_between(x, y1, where=(x < x_crit), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "    else:\n",
        "        plt.fill_between(x, y1, where=(x > x_crit), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "\n",
        "    # Add critical value line\n",
        "    plt.axvline(x_crit, color='black', linestyle='--', label=f'Critical Value = {x_crit:.2f}')\n",
        "\n",
        "    plt.title('Type I and Type II Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print error probabilities\n",
        "    print(f\"Critical Value: {x_crit:.2f}\")\n",
        "    print(f\"Type I Error (Œ±): {alpha:.3f}\")\n",
        "    print(f\"Type II Error (Œ≤): {beta:.3f}\")\n",
        "    print(f\"Power of the Test (1 - Œ≤): {1 - beta:.3f}\")\n"
      ],
      "metadata": {
        "id": "kyJikJkcnP2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  Write a Python program to perform an independent T-test and interpret the results.\n"
      ],
      "metadata": {
        "id": "kcKHbHcdneeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulate two independent samples\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=75, scale=10, size=30)  # Group 1: Mean = 75\n",
        "group2 = np.random.normal(loc=80, scale=12, size=35)  # Group 2: Mean = 80\n",
        "\n",
        "# 2. Perform independent t-test (Welch's t-test for unequal variances)\n",
        "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "# 3. Print summary statistics\n",
        "print(\"Group 1 Mean:\", np.mean(group1))\n",
        "print(\"Group 2 Mean:\", np.mean(group2))\n",
        "print(\"T-statistic:\", round(t_stat, 4))\n",
        "print(\"P-value:\", round(p_value, 4))\n",
        "\n",
        "# 4. Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Since p < {alpha}, we reject the null hypothesis ‚Äî significant difference between means.\")\n",
        "else:\n",
        "    print(f\"Since p >= {alpha}, we fail to reject the null hypothesis ‚Äî no significant difference between means.\")\n",
        "\n",
        "# 5. Optional: Visualization\n",
        "plt.hist(group1, alpha=0.6, label='Group 1', bins=10, color='skyblue', edgecolor='black')\n",
        "plt.hist(group2, alpha=0.6, label='Group 2', bins=10, color='orange', edgecolor='black')\n",
        "plt.axvline(np.mean(group1), color='blue', linestyle='dashed', label='Mean Group 1')\n",
        "plt.axvline(np.mean(group2), color='red', linestyle='dashed', label='Mean Group 2')\n",
        "plt.title('Independent Samples: Distribution of Group 1 vs Group 2')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6acitvMnnpnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  Perform a paired sample T-test using Python and visualize the comparison results.\n"
      ],
      "metadata": {
        "id": "kKOKSFc1ntUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulate paired data (e.g., before and after scores)\n",
        "np.random.seed(42)\n",
        "before = np.random.normal(loc=70, scale=8, size=30)\n",
        "after = before + np.random.normal(loc=5, scale=5, size=30)  # After is higher due to treatment\n",
        "\n",
        "# 2. Perform paired t-test\n",
        "t_stat, p_value = stats.ttest_rel(before, after)\n",
        "\n",
        "# 3. Print statistics\n",
        "print(f\"Mean (Before): {np.mean(before):.2f}\")\n",
        "print(f\"Mean (After):  {np.mean(after):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# 4. Interpret result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Since p < {alpha}, we reject the null hypothesis ‚Äî significant difference between paired means.\")\n",
        "else:\n",
        "    print(f\"Since p >= {alpha}, we fail to reject the null hypothesis ‚Äî no significant difference.\")\n",
        "\n",
        "# 5. Visualization of individual changes\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(len(before)):\n",
        "    plt.plot([0, 1], [before[i], after[i]], color='gray', marker='o')\n",
        "\n",
        "plt.xticks([0, 1], ['Before', 'After'])\n",
        "plt.title('Paired Sample Comparison (Before vs After)')\n",
        "plt.ylabel('Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FAd8vVFrn8nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Simulate data and perform both Z-test and T-test, then compare the results using Python.\n"
      ],
      "metadata": {
        "id": "FPYvLnuhn93J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Simulate data\n",
        "np.random.seed(0)\n",
        "population_mean = 100\n",
        "population_std = 15  # Known for Z-test\n",
        "sample = np.random.normal(loc=102, scale=15, size=25)  # Simulated sample data\n",
        "\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)\n",
        "n = len(sample)\n",
        "\n",
        "# 2. Z-test (one-sample)\n",
        "z_stat = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "# 3. T-test (one-sample)\n",
        "t_stat, t_p_value = stats.ttest_1samp(sample, population_mean)\n",
        "\n",
        "# 4. Print results\n",
        "print(\"Sample Mean:\", round(sample_mean, 2))\n",
        "print(\"Sample Std Dev:\", round(sample_std, 2))\n",
        "print(\"Sample Size:\", n)\n",
        "\n",
        "print(\"\\nüîπ Z-test Results (assumes known population std dev):\")\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {z_p_value:.4f}\")\n",
        "\n",
        "print(\"\\nüîπ T-test Results (uses sample std dev):\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {t_p_value:.4f}\")\n",
        "\n",
        "# 5. Visualization\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "plt.plot(x, stats.norm.pdf(x), label=\"Standard Normal (Z-test)\", color=\"blue\")\n",
        "plt.axvline(z_stat, color=\"blue\", linestyle=\"--\", label=f\"Z = {z_stat:.2f}\")\n",
        "\n",
        "t_df = n - 1\n",
        "plt.plot(x, stats.t.pdf(x, df=t_df), label=f\"Student's t (df={t_df})\", color=\"green\")\n",
        "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"T = {t_stat:.2f}\")\n",
        "\n",
        "plt.title(\"Comparison of Z-test and T-test\")\n",
        "plt.xlabel(\"Test Statistic Value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3rik5xPFoNEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n"
      ],
      "metadata": {
        "id": "5reLmth6oR8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - data: array-like, sample data\n",
        "    - confidence: float, confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple of confidence interval\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # Standard error of the mean\n",
        "    margin = stats.t.ppf((1 + confidence) / 2, df=n-1) * std_err\n",
        "    return (mean - margin, mean + margin)\n"
      ],
      "metadata": {
        "id": "m9unCoN-obCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data.\n"
      ],
      "metadata": {
        "id": "cI2GSLn3oeJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for a sample mean at a given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "    - data: array-like, the sample data\n",
        "    - confidence: float, the confidence level (e.g., 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - moe: margin of error\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    std_err = stats.sem(data)  # Standard error = std dev / sqrt(n)\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "    moe = t_critical * std_err\n",
        "    return moe\n"
      ],
      "metadata": {
        "id": "PjSjC0Tzok6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process."
      ],
      "metadata": {
        "id": "Xs3Mm95wosG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem(prior, likelihood, false_positive, prevalence_complement=None):\n",
        "    \"\"\"\n",
        "    Applies Bayes' Theorem for binary classification.\n",
        "\n",
        "    Parameters:\n",
        "    - prior: P(H) = prior probability of hypothesis\n",
        "    - likelihood: P(D|H) = probability of evidence given hypothesis\n",
        "    - false_positive: P(D|~H) = probability of evidence given hypothesis is false\n",
        "    - prevalence_complement: Optional P(~H). Defaults to (1 - prior)\n",
        "\n",
        "    Returns:\n",
        "    - posterior: P(H|D) = updated belief after evidence\n",
        "    \"\"\"\n",
        "    if prevalence_complement is None:\n",
        "        prevalence_complement = 1 - prior\n",
        "\n",
        "    evidence = likelihood * prior + false_positive * prevalence_complement\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Given data\n",
        "prior = 0.01             # P(Disease)\n",
        "likelihood = 0.99        # P(Positive | Disease)\n",
        "false_positive = 0.05    # P(Positive | No Disease)\n",
        "\n",
        "posterior = bayes_theorem(prior, likelihood, false_positive)\n",
        "print(f\"Posterior Probability (Having disease | Positive test): {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "wra0tfeho_Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.  Perform a Chi-square test for independence between two categorical variables in Python.\n"
      ],
      "metadata": {
        "id": "lUc7J077pAfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# 1. Create a contingency table (observed frequency)\n",
        "# Example: Gender vs Preferred Product\n",
        "# Rows: Gender (Male, Female)\n",
        "# Columns: Product A, B, C\n",
        "\n",
        "data = [[20, 15, 30],  # Male\n",
        "        [25, 30, 20]]  # Female\n",
        "\n",
        "# Optionally wrap in a DataFrame for readability\n",
        "df = pd.DataFrame(data, columns=[\"Product A\", \"Product B\", \"Product C\"], index=[\"Male\", \"Female\"])\n",
        "\n",
        "print(\"Contingency Table:\")\n",
        "print(df)\n",
        "\n",
        "# 2. Perform Chi-square test for independence\n",
        "chi2, p_value, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# 3. Display results\n",
        "print(\"\\nChi-square Statistic:\", round(chi2, 4))\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"P-value:\", round(p_value, 4))\n",
        "print(\"\\nExpected Frequencies (if independent):\")\n",
        "print(pd.DataFrame(expected, columns=df.columns, index=df.index))\n",
        "\n",
        "# 4. Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"\\nSince p < {alpha}, we reject the null hypothesis ‚Äî variables are dependent.\")\n",
        "else:\n",
        "    print(f\"\\nSince p ‚â• {alpha}, we fail to reject the null hypothesis ‚Äî variables are independent.\")\n"
      ],
      "metadata": {
        "id": "nIOYdui1pFge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data.\n"
      ],
      "metadata": {
        "id": "HGaJUCKMpPHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate expected frequencies for a Chi-square test for independence.\n",
        "\n",
        "    Parameters:\n",
        "    - observed: 2D list or numpy array (contingency table)\n",
        "\n",
        "    Returns:\n",
        "    - expected: 2D numpy array of expected frequencies\n",
        "    \"\"\"\n",
        "    observed = np.array(observed)\n",
        "    row_totals = observed.sum(axis=1).reshape(-1, 1)  # Column vector\n",
        "    col_totals = observed.sum(axis=0).reshape(1, -1)  # Row vector\n",
        "    total = observed.sum()\n",
        "\n",
        "    expected = (row_totals @ col_totals) / total\n",
        "    return expected\n",
        "\n",
        "# Example: Observed data (contingency table)\n",
        "# Rows: Gender (Male, Female)\n",
        "# Columns: Product A, B, C\n",
        "observed_data = [[20, 15, 30],\n",
        "                 [25, 30, 20]]\n",
        "\n",
        "# Calculate expected frequencies\n",
        "expected = calculate_expected_frequencies(observed_data)\n",
        "\n",
        "# Convert to DataFrame for better display\n",
        "observed_df = pd.DataFrame(observed_data, columns=[\"Product A\", \"Product B\", \"Product C\"], index=[\"Male\", \"Female\"])\n",
        "expected_df = pd.DataFrame(expected, columns=observed_df.columns, index=observed_df.index)\n",
        "\n",
        "# Display\n",
        "print(\"Observed Frequencies:\")\n",
        "print(observed_df)\n",
        "print(\"\\nExpected Frequencies (Assuming Independence):\")\n",
        "print(expected_df.round(2))\n"
      ],
      "metadata": {
        "id": "Lqi1M-RDpVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution."
      ],
      "metadata": {
        "id": "ucubCmuIpcY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# 1. Observed data from experiment\n",
        "observed = np.array([10, 9, 8, 11, 12, 10])  # counts of each face of a die\n",
        "\n",
        "# 2. Expected frequencies under uniform distribution\n",
        "n = observed.sum()\n",
        "k = len(observed)\n",
        "expected = np.array([n / k] * k)  # uniform: each category expected equally\n",
        "\n",
        "# 3. Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# 4. Display results\n",
        "print(\"Observed Frequencies:\", observed)\n",
        "print(\"Expected Frequencies:\", expected)\n",
        "print(f\"\\nChi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# 5. Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"\\nSince p < {alpha}, reject the null hypothesis ‚Äî the data does NOT fit the expected distribution.\")\n",
        "else:\n",
        "    print(f\"\\nSince p ‚â• {alpha}, fail to reject the null hypothesis ‚Äî the data fits the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "MHa84PKnpj9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}